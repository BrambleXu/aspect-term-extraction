{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# raw text to list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/smap10/Project/aspect-extraction/notebooks')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Path.cwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/smap10/Project/aspect-extraction')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Path.cwd().parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/smap10/Project/aspect-extraction/raw-data/semeval-2016/train.xml')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_file = Path.cwd().parent.joinpath('raw-data/semeval-2016/train.xml')\n",
    "train_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = None\n",
    "with train_file.open(encoding=\"utf-8\") as f:\n",
    "    soup = BeautifulSoup(f.read().strip(), \"lxml-xml\")\n",
    "\n",
    "if soup is None:\n",
    "    raise Exception(\"Can't read xml file\")\n",
    "\n",
    "sentence_nodes = soup.find_all(\"sentence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentence_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sentence id=\"1004293:0\">\n",
      "<text>Judging from previous posts this used to be a good place, but not any longer.</text>\n",
      "<Opinions>\n",
      "<Opinion category=\"RESTAURANT#GENERAL\" from=\"51\" polarity=\"negative\" target=\"place\" to=\"56\"/>\n",
      "</Opinions>\n",
      "</sentence>\n",
      "\n",
      "<sentence id=\"1004293:1\">\n",
      "<text>We, there were four of us, arrived at noon - the place was empty - and the staff acted like we were imposing on them and they were very rude.</text>\n",
      "<Opinions>\n",
      "<Opinion category=\"SERVICE#GENERAL\" from=\"75\" polarity=\"negative\" target=\"staff\" to=\"80\"/>\n",
      "</Opinions>\n",
      "</sentence>\n",
      "\n",
      "<sentence id=\"1004293:2\">\n",
      "<text>They never brought us complimentary noodles, ignored repeated requests for sugar, and threw our dishes on the table.</text>\n",
      "<Opinions>\n",
      "<Opinion category=\"SERVICE#GENERAL\" from=\"0\" polarity=\"negative\" target=\"NULL\" to=\"0\"/>\n",
      "</Opinions>\n",
      "</sentence>\n",
      "\n",
      "<sentence id=\"1004293:3\">\n",
      "<text>The food was lousy - too sweet or too salty and the portions tiny.</text>\n",
      "<Opinions>\n",
      "<Opinion category=\"FOOD#QUALITY\" from=\"4\" polarity=\"negative\" target=\"food\" to=\"8\"/>\n",
      "<Opinion category=\"FOOD#STYLE_OPTIONS\" from=\"52\" polarity=\"negative\" target=\"portions\" to=\"60\"/>\n",
      "</Opinions>\n",
      "</sentence>\n",
      "\n",
      "<sentence id=\"1004293:4\">\n",
      "<text>After all that, they complained to me about the small tip.</text>\n",
      "<Opinions>\n",
      "<Opinion category=\"SERVICE#GENERAL\" from=\"0\" polarity=\"negative\" target=\"NULL\" to=\"0\"/>\n",
      "</Opinions>\n",
      "</sentence>\n",
      "\n",
      "<sentence id=\"1004293:5\">\n",
      "<text>Avoid this place!</text>\n",
      "<Opinions>\n",
      "<Opinion category=\"RESTAURANT#GENERAL\" from=\"11\" polarity=\"negative\" target=\"place\" to=\"16\"/>\n",
      "</Opinions>\n",
      "</sentence>\n",
      "\n",
      "<sentence id=\"1014458:0\">\n",
      "<text>I have eaten at Saul, many times, the food is always consistently, outrageously good.</text>\n",
      "<Opinions>\n",
      "<Opinion category=\"FOOD#QUALITY\" from=\"38\" polarity=\"positive\" target=\"food\" to=\"42\"/>\n",
      "</Opinions>\n",
      "</sentence>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, node in enumerate(sentence_nodes):\n",
    "    print(node)\n",
    "    print()\n",
    "    if i > 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sentence id=\"1041457:0\">\n",
      "<text>I had my eyes on this place, promising myself I will one day 'give it a try.' </text>\n",
      "</sentence>\n",
      "<sentence OutOfScope=\"TRUE\" id=\"1041457:5\">\n",
      "<text>Anyways, if you're in the neighborhood to eat good food, I wouldn't waste my time trying to find something, rather go across the street to Tamari.</text>\n",
      "</sentence>\n",
      "<sentence id=\"1053543:0\">\n",
      "<text>We ate outside at Haru's Sake bar because Haru's restaurant next door was overflowing.</text>\n",
      "</sentence>\n",
      "<sentence id=\"1053543:1\">\n",
      "<text>What's the difference between the two?</text>\n",
      "</sentence>\n"
     ]
    }
   ],
   "source": [
    "# some sentence only contain text tag, no Opinions tag\n",
    "i = 0\n",
    "for n in sentence_nodes:\n",
    "    if not n.find('Opinions'):\n",
    "        print(n)    \n",
    "        i += 1\n",
    "        if i > 3:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "i = 0\n",
    "for n in sentence_nodes:\n",
    "    i += 1\n",
    "    sentence = {}\n",
    "    aspect_term = []\n",
    "    sentence['id'] = i\n",
    "    sentence['text'] = n.find('text').string\n",
    "    if n.find('Opinions'):\n",
    "        for c in n.find('Opinions').contents:\n",
    "            if c.name == 'Opinion':\n",
    "                if c['target'] not in aspect_term:\n",
    "                    aspect_term.append(c['target'])\n",
    "\n",
    "    sentence['aspect'] = aspect_term\n",
    "    sentences.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'aspect': ['place'],\n",
       "  'id': 1,\n",
       "  'text': 'Judging from previous posts this used to be a good place, but not any longer.'},\n",
       " {'aspect': ['staff'],\n",
       "  'id': 2,\n",
       "  'text': 'We, there were four of us, arrived at noon - the place was empty - and the staff acted like we were imposing on them and they were very rude.'},\n",
       " {'aspect': ['NULL'],\n",
       "  'id': 3,\n",
       "  'text': 'They never brought us complimentary noodles, ignored repeated requests for sugar, and threw our dishes on the table.'},\n",
       " {'aspect': ['food', 'portions'],\n",
       "  'id': 4,\n",
       "  'text': 'The food was lousy - too sweet or too salty and the portions tiny.'},\n",
       " {'aspect': ['NULL'],\n",
       "  'id': 5,\n",
       "  'text': 'After all that, they complained to me about the small tip.'}]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "791\n",
      "1209\n"
     ]
    }
   ],
   "source": [
    "# No sentence contain two NULL target (aspect term)\n",
    "aspect_zero = 0\n",
    "aspect_one = 0\n",
    "\n",
    "for s in sentences:\n",
    "    # aspect == [] or aspect == ['NULL']\n",
    "    if len(s['aspect'])==0 or s['aspect'][0] == 'NULL':\n",
    "        aspect_zero += 1\n",
    "    else:\n",
    "        aspect_one += 1\n",
    "        \n",
    "print(len(sentences)) # Total 2000 sentences\n",
    "print(aspect_zero) # xxx sentences have no aspect term\n",
    "print(aspect_one) # xxx sentences have at least 1 aspect term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print aspect and text \n",
    "i = 0\n",
    "for s in sentences:\n",
    "    if len(s['aspect']) > 1:\n",
    "        i += 1\n",
    "        print(s['aspect'])\n",
    "        print(s['text'])\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'aspect': ['place'],\n",
       "  'id': 1,\n",
       "  'text': 'Judging from previous posts this used to be a good place, but not any longer.'},\n",
       " {'aspect': ['staff'],\n",
       "  'id': 2,\n",
       "  'text': 'We, there were four of us, arrived at noon - the place was empty - and the staff acted like we were imposing on them and they were very rude.'},\n",
       " {'aspect': ['NULL'],\n",
       "  'id': 3,\n",
       "  'text': 'They never brought us complimentary noodles, ignored repeated requests for sugar, and threw our dishes on the table.'},\n",
       " {'aspect': ['food', 'portions'],\n",
       "  'id': 4,\n",
       "  'text': 'The food was lousy - too sweet or too salty and the portions tiny.'},\n",
       " {'aspect': ['NULL'],\n",
       "  'id': 5,\n",
       "  'text': 'After all that, they complained to me about the small tip.'},\n",
       " {'aspect': ['place'], 'id': 6, 'text': 'Avoid this place!'},\n",
       " {'aspect': ['food'],\n",
       "  'id': 7,\n",
       "  'text': 'I have eaten at Saul, many times, the food is always consistently, outrageously good.'},\n",
       " {'aspect': ['Saul'],\n",
       "  'id': 8,\n",
       "  'text': 'Saul is the best restaurant on Smith Street and in Brooklyn.'},\n",
       " {'aspect': ['foie gras terrine with figs', 'duck confit'],\n",
       "  'id': 9,\n",
       "  'text': 'The duck confit is always amazing and the foie gras terrine with figs was out of this world.'},\n",
       " {'aspect': ['wine list'],\n",
       "  'id': 10,\n",
       "  'text': 'The wine list is interesting and has many good values.'},\n",
       " {'aspect': ['NULL'],\n",
       "  'id': 11,\n",
       "  'text': 'For the price, you cannot eat this well in Manhattan.'},\n",
       " {'aspect': ['restaurant'],\n",
       "  'id': 12,\n",
       "  'text': 'I was very disappointed with this restaurant.'},\n",
       " {'aspect': ['cart attendant'],\n",
       "  'id': 13,\n",
       "  'text': 'Ive asked a cart attendant for a lotus leaf wrapped rice and she replied back rice and just walked away.'},\n",
       " {'aspect': ['NULL'],\n",
       "  'id': 14,\n",
       "  'text': 'I had to ask her three times before she finally came back with the dish Ive requested.'},\n",
       " {'aspect': ['Food'], 'id': 15, 'text': 'Food was okay, nothing great.'},\n",
       " {'aspect': ['Chow fun', 'pork shu mai', 'NULL'],\n",
       "  'id': 16,\n",
       "  'text': 'Chow fun was dry; pork shu mai was more than usually greasy and had to share a table with loud and rude family. '},\n",
       " {'aspect': ['place'],\n",
       "  'id': 17,\n",
       "  'text': 'I/we will never go back to this place again.'},\n",
       " {'aspect': ['Fish'],\n",
       "  'id': 18,\n",
       "  'text': 'Went on a 3 day oyster binge, with Fish bringing up the closing, and I am so glad this was the place it O trip ended, because it was so great!'},\n",
       " {'aspect': ['Service', 'oysters', 'NULL'],\n",
       "  'id': 19,\n",
       "  'text': \"Service was devine, oysters where a sensual as they come, and the price can't be beat!!!\"},\n",
       " {'aspect': ['NULL'], 'id': 20, 'text': \"You can't go wrong here.\"}]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  raw text to list - sum it up\n",
    "We have total 2000 sentences, and only 1209 sentences have 1 aspect term at least. Sum above to one function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw2dict(sentence_nodes):\n",
    "    \"\"\"\n",
    "    Input: a soup object, e.g. soup.find_all(\"sentence\")\n",
    "    Output: a list of dictionaries, contains id, text, aspect terms\n",
    "    \"\"\"\n",
    "    sentences = []\n",
    "    i = 0\n",
    "    for n in sentence_nodes:\n",
    "        i += 1\n",
    "        sentence = {}\n",
    "        aspect_term = []\n",
    "        sentence['id'] = i\n",
    "        sentence['text'] = n.find('text').string\n",
    "        if n.find('Opinions'):\n",
    "            for c in n.find('Opinions').contents:\n",
    "                if c.name == 'Opinion':\n",
    "                    if c['target'] not in aspect_term:\n",
    "                        aspect_term.append(c['target'])\n",
    "\n",
    "        sentence['aspect'] = aspect_term\n",
    "        sentences.append(sentence)\n",
    "        \n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = Path.cwd().parent.joinpath('raw-data/semeval-2016/train.xml')\n",
    "soup = None\n",
    "with train_file.open(encoding=\"utf-8\") as f:\n",
    "    soup = BeautifulSoup(f.read().strip(), \"lxml-xml\")\n",
    "\n",
    "if soup is None:\n",
    "    raise Exception(\"Can't read xml file\")\n",
    "\n",
    "sentence_nodes = soup.find_all(\"sentence\")\n",
    "sentences = raw2dict(sentence_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'aspect': ['place'],\n",
       "  'id': 1,\n",
       "  'text': 'Judging from previous posts this used to be a good place, but not any longer.'},\n",
       " {'aspect': ['staff'],\n",
       "  'id': 2,\n",
       "  'text': 'We, there were four of us, arrived at noon - the place was empty - and the staff acted like we were imposing on them and they were very rude.'},\n",
       " {'aspect': ['NULL'],\n",
       "  'id': 3,\n",
       "  'text': 'They never brought us complimentary noodles, ignored repeated requests for sugar, and threw our dishes on the table.'},\n",
       " {'aspect': ['food', 'portions'],\n",
       "  'id': 4,\n",
       "  'text': 'The food was lousy - too sweet or too salty and the portions tiny.'},\n",
       " {'aspect': ['NULL'],\n",
       "  'id': 5,\n",
       "  'text': 'After all that, they complained to me about the small tip.'}]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# list to dataframe\n",
    "\n",
    "the dataframe should have 3 columns, sentence id, word, tag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'aspect': ['place'],\n",
       "  'id': 1,\n",
       "  'text': 'Judging from previous posts this used to be a good place, but not any longer.'},\n",
       " {'aspect': ['staff'],\n",
       "  'id': 2,\n",
       "  'text': 'We, there were four of us, arrived at noon - the place was empty - and the staff acted like we were imposing on them and they were very rude.'},\n",
       " {'aspect': ['NULL'],\n",
       "  'id': 3,\n",
       "  'text': 'They never brought us complimentary noodles, ignored repeated requests for sugar, and threw our dishes on the table.'},\n",
       " {'aspect': ['food', 'portions'],\n",
       "  'id': 4,\n",
       "  'text': 'The food was lousy - too sweet or too salty and the portions tiny.'},\n",
       " {'aspect': ['NULL'],\n",
       "  'id': 5,\n",
       "  'text': 'After all that, they complained to me about the small tip.'}]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = sentences[:5]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Judging from previous posts this used to be a good place, but not any longer.\n",
      "['judging', 'from', 'previous', 'posts', 'this', 'used', 'to', 'be', 'a', 'good', 'place', ',', 'but', 'not', 'any', 'longer', '.']\n"
     ]
    }
   ],
   "source": [
    "# split sentences to words, and contain the punctuations\n",
    "import re\n",
    "s = sentences[0]['text']\n",
    "print(s)\n",
    "\n",
    "s = re.sub('([.,!?()])', r' \\1 ', s) # match the punctuation characters and surround them by spaces,\n",
    "s = re.sub('\\s{2,}', ' ', s)         # collapse multiple spaces to one space\n",
    "print(s.lower().split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a example to assign IOB format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a good place', 'posts']"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = ['judging', 'from', 'previous', 'posts', 'this', 'used', 'to', 'be', 'a', 'good', 'place', ',', 'but', 'not', 'any', 'longer', '.']\n",
    "aspects = ['a good place', 'Posts']\n",
    "\n",
    "aspects = [x.lower() for x in aspect]\n",
    "aspects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "tags = ['O'] * len(s)\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "a\n",
      "8 0\n",
      "good\n",
      "9 8\n",
      "place\n",
      "10 9\n",
      "posts\n",
      "3 0\n",
      "['O', 'O', 'O', 'B', 'O', 'O', 'O', 'O', 'B', 'I', 'I', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "tags = ['O'] * len(s)\n",
    "print(tags)\n",
    "\n",
    "for aspect in aspects:\n",
    "    pre_index = 0\n",
    "    for word in s: \n",
    "        if word in aspect: # 'good' in 'a good place'\n",
    "            print(word)\n",
    "            cur_index = s.index(word) # \n",
    "            print(cur_index, pre_index)\n",
    "            if cur_index - pre_index == 1: # good after a\n",
    "                tags[cur_index] = 'I'\n",
    "#                 print('I')\n",
    "            else:                       # a after no aspect words\n",
    "                tags[cur_index] = 'B'\n",
    "            pre_index = cur_index \n",
    "            \n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tagging_IOB(s, aspects):\n",
    "    \"\"\"Assigning IOB tag to each word in s\n",
    "    Input: \n",
    "        s: sentences, a list of words, e.g. ['judging', 'from', 'previous', 'posts']\n",
    "        aspects: a list of aspect term, e.g. ['a good place', 'Posts']\n",
    "    Output:\n",
    "        tag: a list of tag, e.g. ['O', 'O', 'O', 'B']\n",
    "    \"\"\"\n",
    "    tags = ['O'] * len(s)\n",
    "\n",
    "    for aspect in aspects:\n",
    "        pre_index = 0\n",
    "        for word in s: \n",
    "            if word in aspect: # 'good' in 'a good place'\n",
    "                cur_index = s.index(word) \n",
    "                if cur_index - pre_index == 1: # inside an aspect term\n",
    "                    tags[cur_index] = 'I'\n",
    "                else:                       # beginning of an aspect term\n",
    "                    tags[cur_index] = 'B'\n",
    "                pre_index = cur_index \n",
    "    return tags\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a example to assign IOB format ----end------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def split2words(s_text):\n",
    "    \"\"\"Split string with white and prereserve the punctuation\n",
    "    Input:\n",
    "        s_text: string, a sentence, e.g. Judging from previous posts this used to be a good place, but not any longer.\n",
    "    Output:\n",
    "        words: a list of words, e.g. ['judging', 'from', 'previous', 'posts', 'this', 'used', 'to', 'be', 'a', 'good', 'place', ',', 'but', 'not', 'any', 'longer', '.']\n",
    "    \"\"\"\n",
    "    s_text = re.sub('([.,!?()])', r' \\1 ', s_text) # match the punctuation characters and surround them by spaces,\n",
    "    s_text = re.sub('\\s{2,}', ' ', s_text)         # collapse multiple spaces to one space\n",
    "    words = s_text.lower().split()\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "sentences_df = []\n",
    "for s in sentences:\n",
    "    sentence = {}\n",
    "    sentence['Sentence #'] = s['id']\n",
    "    sentence['Word'] = split2words(s['text']) \n",
    "    s_length = len(sentence['Word']) # the length of sentence, used to generate tag\n",
    "    if len(s['aspect'])==0 or s['aspect'][0] == 'NULL':\n",
    "        sentence['Tag'] = ['O'] * s_length\n",
    "    else:\n",
    "        aspect_terms = [x.lower() for x in s['aspect']]  # IOB format if aspect exist\n",
    "        sentence['Tag'] = tagging_IOB(sentence['Word'], aspect_terms)\n",
    "    \n",
    "    sentences_df.append(sentence)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# list to dataframe - sum it up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_of_dic(sentences):\n",
    "    \"\"\"Convert list of dict to dataframe\n",
    "    Input: \n",
    "        sentences: a list of dictionaries, contains id, text, aspect terms. The output of raw2dict\n",
    "    Output:\n",
    "        data: a dataframe with three columns, sentence id, words, tag with IOB format\n",
    "    \"\"\"\n",
    "    data = pd.DataFrame()\n",
    "    for s in sentences:\n",
    "        sentence = {}\n",
    "        sentence['Sentence #'] = s['id']\n",
    "        sentence['Word'] = split2words(s['text'])  # split text to words\n",
    "        s_length = len(sentence['Word']) # the length of sentence, used to generate tag\n",
    "        if len(s['aspect'])==0 or s['aspect'][0] == 'NULL': # tagging: if no aspect term\n",
    "            sentence['Tag'] = ['O'] * s_length\n",
    "        else:                                               # IOB format tag if aspect exist\n",
    "            aspect_terms = [x.lower() for x in s['aspect']]  \n",
    "            sentence['Tag'] = tagging_IOB(sentence['Word'], aspect_terms)\n",
    "\n",
    "        # convert each setence to dataframe \n",
    "        sentence_df = pd.DataFrame.from_dict(sentence)\n",
    "        data = data.append(sentence_df, ignore_index=True)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for s in sentences_df:\n",
    "#     s_id = s['Sentence #']\n",
    "#     s['Sentence #'] = [s_id] * len(s['Tag'])\n",
    "    \n",
    "# sentences_df[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Sentence #': 1990,\n",
       " 'Tag': ['O', 'O', 'O', 'O', 'B', 'O'],\n",
       " 'Word': ['i', 'generally', 'like', 'this', 'place', '.']}"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_df[1989]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>judging</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>from</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>previous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>posts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>used</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>place</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>but</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>not</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>any</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>longer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence # Tag      Word\n",
       "0            1   O   judging\n",
       "1            1   O      from\n",
       "2            1   O  previous\n",
       "3            1   O     posts\n",
       "4            1   O      this\n",
       "5            1   O      used\n",
       "6            1   O        to\n",
       "7            1   O        be\n",
       "8            1   B         a\n",
       "9            1   O      good\n",
       "10           1   B     place\n",
       "11           1   O         ,\n",
       "12           1   O       but\n",
       "13           1   O       not\n",
       "14           1   O       any\n",
       "15           1   O    longer\n",
       "16           1   O         ."
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(sentences_df[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame()\n",
    "for s in sentences_df:\n",
    "    s_df = pd.DataFrame.from_dict(s)\n",
    "    data = data.append(s_df, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>judging</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>from</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>previous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>posts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>used</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>place</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>but</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>not</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>any</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>longer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>O</td>\n",
       "      <td>we</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>O</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2</td>\n",
       "      <td>O</td>\n",
       "      <td>there</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>O</td>\n",
       "      <td>were</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>O</td>\n",
       "      <td>four</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>O</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>O</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2</td>\n",
       "      <td>O</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>O</td>\n",
       "      <td>arrived</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2</td>\n",
       "      <td>O</td>\n",
       "      <td>at</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2</td>\n",
       "      <td>O</td>\n",
       "      <td>noon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2</td>\n",
       "      <td>O</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2</td>\n",
       "      <td>O</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28616</th>\n",
       "      <td>1999</td>\n",
       "      <td>O</td>\n",
       "      <td>minutes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28617</th>\n",
       "      <td>1999</td>\n",
       "      <td>O</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28618</th>\n",
       "      <td>1999</td>\n",
       "      <td>O</td>\n",
       "      <td>even</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28619</th>\n",
       "      <td>1999</td>\n",
       "      <td>O</td>\n",
       "      <td>though</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28620</th>\n",
       "      <td>1999</td>\n",
       "      <td>O</td>\n",
       "      <td>we</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28621</th>\n",
       "      <td>1999</td>\n",
       "      <td>O</td>\n",
       "      <td>were</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28622</th>\n",
       "      <td>1999</td>\n",
       "      <td>O</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28623</th>\n",
       "      <td>1999</td>\n",
       "      <td>O</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28624</th>\n",
       "      <td>1999</td>\n",
       "      <td>O</td>\n",
       "      <td>three</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28625</th>\n",
       "      <td>1999</td>\n",
       "      <td>O</td>\n",
       "      <td>occupied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28626</th>\n",
       "      <td>1999</td>\n",
       "      <td>O</td>\n",
       "      <td>tables</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28627</th>\n",
       "      <td>1999</td>\n",
       "      <td>O</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28628</th>\n",
       "      <td>2000</td>\n",
       "      <td>O</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28629</th>\n",
       "      <td>2000</td>\n",
       "      <td>O</td>\n",
       "      <td>wish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28630</th>\n",
       "      <td>2000</td>\n",
       "      <td>O</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28631</th>\n",
       "      <td>2000</td>\n",
       "      <td>O</td>\n",
       "      <td>could</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28632</th>\n",
       "      <td>2000</td>\n",
       "      <td>O</td>\n",
       "      <td>like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28633</th>\n",
       "      <td>2000</td>\n",
       "      <td>O</td>\n",
       "      <td>this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28634</th>\n",
       "      <td>2000</td>\n",
       "      <td>B</td>\n",
       "      <td>place</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28635</th>\n",
       "      <td>2000</td>\n",
       "      <td>O</td>\n",
       "      <td>more</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28636</th>\n",
       "      <td>2000</td>\n",
       "      <td>O</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28637</th>\n",
       "      <td>2000</td>\n",
       "      <td>O</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28638</th>\n",
       "      <td>2000</td>\n",
       "      <td>O</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28639</th>\n",
       "      <td>2000</td>\n",
       "      <td>O</td>\n",
       "      <td>wish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28640</th>\n",
       "      <td>2000</td>\n",
       "      <td>O</td>\n",
       "      <td>someone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28641</th>\n",
       "      <td>2000</td>\n",
       "      <td>O</td>\n",
       "      <td>would</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28642</th>\n",
       "      <td>2000</td>\n",
       "      <td>O</td>\n",
       "      <td>retrain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28643</th>\n",
       "      <td>2000</td>\n",
       "      <td>O</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28644</th>\n",
       "      <td>2000</td>\n",
       "      <td>B</td>\n",
       "      <td>staff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28645</th>\n",
       "      <td>2000</td>\n",
       "      <td>O</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28646 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Sentence # Tag      Word\n",
       "0               1   O   judging\n",
       "1               1   O      from\n",
       "2               1   O  previous\n",
       "3               1   O     posts\n",
       "4               1   O      this\n",
       "5               1   O      used\n",
       "6               1   O        to\n",
       "7               1   O        be\n",
       "8               1   B         a\n",
       "9               1   O      good\n",
       "10              1   B     place\n",
       "11              1   O         ,\n",
       "12              1   O       but\n",
       "13              1   O       not\n",
       "14              1   O       any\n",
       "15              1   O    longer\n",
       "16              1   O         .\n",
       "17              2   O        we\n",
       "18              2   O         ,\n",
       "19              2   O     there\n",
       "20              2   O      were\n",
       "21              2   O      four\n",
       "22              2   O        of\n",
       "23              2   O        us\n",
       "24              2   O         ,\n",
       "25              2   O   arrived\n",
       "26              2   O        at\n",
       "27              2   O      noon\n",
       "28              2   O         -\n",
       "29              2   O       the\n",
       "...           ...  ..       ...\n",
       "28616        1999   O   minutes\n",
       "28617        1999   O         ,\n",
       "28618        1999   O      even\n",
       "28619        1999   O    though\n",
       "28620        1999   O        we\n",
       "28621        1999   O      were\n",
       "28622        1999   O       one\n",
       "28623        1999   O        of\n",
       "28624        1999   O     three\n",
       "28625        1999   O  occupied\n",
       "28626        1999   O    tables\n",
       "28627        1999   O         .\n",
       "28628        2000   O         i\n",
       "28629        2000   O      wish\n",
       "28630        2000   O         i\n",
       "28631        2000   O     could\n",
       "28632        2000   O      like\n",
       "28633        2000   O      this\n",
       "28634        2000   B     place\n",
       "28635        2000   O      more\n",
       "28636        2000   O         ,\n",
       "28637        2000   O       and\n",
       "28638        2000   O         i\n",
       "28639        2000   O      wish\n",
       "28640        2000   O   someone\n",
       "28641        2000   O     would\n",
       "28642        2000   O   retrain\n",
       "28643        2000   O       the\n",
       "28644        2000   B     staff\n",
       "28645        2000   O         .\n",
       "\n",
       "[28646 rows x 3 columns]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file = Path.cwd().parent.joinpath('data/semeval-2016/train.csv')\n",
    "\n",
    "data.to_csv(save_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
