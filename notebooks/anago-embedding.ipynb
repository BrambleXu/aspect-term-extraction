{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "import anago\n",
    "from anago.utils import load_data_and_labels, load_glove\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/smap10/Project/aspect-extraction/data/semeval-2016/train.csv\n",
      "/Users/smap10/Project/aspect-extraction/data/semeval-2016/test.csv\n"
     ]
    }
   ],
   "source": [
    "train_path = Path.cwd().parent.joinpath('data/semeval-2016/train.csv')\n",
    "test_path = Path.cwd().parent.joinpath('data/semeval-2016/test.csv')\n",
    "print(train_path)\n",
    "print(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "data_train = pd.read_csv(train_path)\n",
    "data_test = pd.read_csv(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28641</th>\n",
       "      <td>2000</td>\n",
       "      <td>O</td>\n",
       "      <td>would</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28642</th>\n",
       "      <td>2000</td>\n",
       "      <td>O</td>\n",
       "      <td>retrain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28643</th>\n",
       "      <td>2000</td>\n",
       "      <td>O</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28644</th>\n",
       "      <td>2000</td>\n",
       "      <td>B</td>\n",
       "      <td>staff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28645</th>\n",
       "      <td>2000</td>\n",
       "      <td>O</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Sentence # Tag     Word\n",
       "28641        2000   O    would\n",
       "28642        2000   O  retrain\n",
       "28643        2000   O      the\n",
       "28644        2000   B    staff\n",
       "28645        2000   O        ."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9864</th>\n",
       "      <td>676</td>\n",
       "      <td>O</td>\n",
       "      <td>was</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9865</th>\n",
       "      <td>676</td>\n",
       "      <td>O</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9866</th>\n",
       "      <td>676</td>\n",
       "      <td>O</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9867</th>\n",
       "      <td>676</td>\n",
       "      <td>O</td>\n",
       "      <td>too</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9868</th>\n",
       "      <td>676</td>\n",
       "      <td>O</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sentence # Tag  Word\n",
       "9864         676   O   was\n",
       "9865         676   O  good\n",
       "9866         676   O     ,\n",
       "9867         676   O   too\n",
       "9868         676   O     ."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df2data(df):\n",
    "    \"\"\"Read data and labels from dataframe\n",
    "    Input:\n",
    "        df: three columns, ['Sentence #', 'Tag', 'Word']\n",
    "    Output:\n",
    "        data: datasize * ['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.']\n",
    "        label: datasize * ['B-ORG', 'O', 'B-MISC', 'O', 'O', 'O', 'B-MISC', 'O', 'O']\n",
    "    \"\"\"\n",
    "    agg_func = lambda s: [(w, t) for w, t in zip(s[\"Word\"].values.tolist(),\n",
    "                                                 s[\"Tag\"].values.tolist())]\n",
    "    grouped = df.groupby(\"Sentence #\").apply(agg_func)\n",
    "    data = [[w[0] for w in s] for s in grouped]\n",
    "    label = [[w[1] for w in s] for s in grouped]  \n",
    "    \n",
    "    return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = df2data(data_train)\n",
    "x_test, y_test = df2data(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "676\n",
      "['judging', 'from', 'previous', 'posts', 'this', 'used', 'to', 'be', 'a', 'good', 'place', ',', 'but', 'not', 'any', 'longer', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B', 'O', 'B', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train))\n",
    "print(len(x_test))\n",
    "print(x_train[0])\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "# x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.1, random_state=42)\n",
    "# print(len(x_train))\n",
    "# print(len(x_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_PATH = '../embedding_weights/glove.840B.300d.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = load_glove(EMBEDDING_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",: [-0.082752  0.67204  -0.14987  -0.064983  0.056491]\n",
      ".: [ 0.012001  0.20751  -0.12578  -0.59325   0.12525 ]\n",
      "the: [ 0.27204  -0.06203  -0.1884    0.023225 -0.018158]\n",
      "and: [-0.18567   0.066008 -0.25209  -0.11725   0.26513 ]\n",
      "to: [ 0.31924   0.06316  -0.27858   0.2612    0.079248]\n"
     ]
    }
   ],
   "source": [
    "for i, (key, value) in enumerate(embeddings.items()):\n",
    "    print('{0}: {1}'.format(key, value[:5]))\n",
    "    if i > 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2196016"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "63/63 [==============================] - 19s 303ms/step - loss: 4.3553\n",
      " - f1: 31.67\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          B       0.49      0.22      0.30       600\n",
      "          I       0.37      0.32      0.34       269\n",
      "\n",
      "avg / total       0.45      0.25      0.31       869\n",
      "\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 15s 235ms/step - loss: 4.2204\n",
      " - f1: 44.32\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          B       0.60      0.39      0.47       600\n",
      "          I       0.46      0.34      0.39       269\n",
      "\n",
      "avg / total       0.56      0.37      0.44       869\n",
      "\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 15s 234ms/step - loss: 4.1825\n",
      " - f1: 48.93\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          B       0.61      0.42      0.50       600\n",
      "          I       0.53      0.43      0.47       269\n",
      "\n",
      "avg / total       0.58      0.42      0.49       869\n",
      "\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 13s 214ms/step - loss: 4.1593\n",
      " - f1: 51.91\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          B       0.66      0.42      0.51       600\n",
      "          I       0.57      0.51      0.54       269\n",
      "\n",
      "avg / total       0.63      0.45      0.52       869\n",
      "\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 14s 227ms/step - loss: 4.1429\n",
      " - f1: 51.59\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          B       0.74      0.38      0.50       600\n",
      "          I       0.69      0.46      0.55       269\n",
      "\n",
      "avg / total       0.72      0.40      0.51       869\n",
      "\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 13s 214ms/step - loss: 4.1221\n",
      " - f1: 54.31\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          B       0.75      0.39      0.52       600\n",
      "          I       0.66      0.54      0.59       269\n",
      "\n",
      "avg / total       0.72      0.44      0.54       869\n",
      "\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 13s 210ms/step - loss: 4.1074\n",
      " - f1: 55.30\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          B       0.68      0.46      0.55       600\n",
      "          I       0.66      0.49      0.56       269\n",
      "\n",
      "avg / total       0.68      0.47      0.55       869\n",
      "\n",
      "Epoch 8/50\n",
      "63/63 [==============================] - 13s 211ms/step - loss: 4.0984\n",
      " - f1: 54.14\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          B       0.71      0.42      0.53       600\n",
      "          I       0.71      0.46      0.56       269\n",
      "\n",
      "avg / total       0.71      0.44      0.54       869\n",
      "\n",
      "Epoch 9/50\n",
      "63/63 [==============================] - 13s 212ms/step - loss: 4.0862\n",
      " - f1: 57.99\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          B       0.58      0.58      0.58       600\n",
      "          I       0.61      0.55      0.58       269\n",
      "\n",
      "avg / total       0.59      0.57      0.58       869\n",
      "\n",
      "Epoch 10/50\n",
      "63/63 [==============================] - 15s 238ms/step - loss: 4.0795\n",
      " - f1: 58.19\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          B       0.67      0.50      0.57       600\n",
      "          I       0.64      0.57      0.60       269\n",
      "\n",
      "avg / total       0.66      0.52      0.58       869\n",
      "\n",
      "Epoch 11/50\n",
      "63/63 [==============================] - 13s 214ms/step - loss: 4.0697\n",
      " - f1: 57.45\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          B       0.61      0.52      0.56       600\n",
      "          I       0.67      0.56      0.61       269\n",
      "\n",
      "avg / total       0.63      0.53      0.57       869\n",
      "\n",
      "Epoch 12/50\n",
      "63/63 [==============================] - 16s 251ms/step - loss: 4.0621\n",
      " - f1: 56.59\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          B       0.68      0.47      0.55       600\n",
      "          I       0.66      0.54      0.59       269\n",
      "\n",
      "avg / total       0.67      0.49      0.57       869\n",
      "\n",
      "Epoch 13/50\n",
      "63/63 [==============================] - 15s 234ms/step - loss: 4.0583\n",
      " - f1: 57.30\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          B       0.60      0.53      0.56       600\n",
      "          I       0.63      0.57      0.60       269\n",
      "\n",
      "avg / total       0.61      0.54      0.57       869\n",
      "\n",
      "Epoch 14/50\n",
      "63/63 [==============================] - 16s 260ms/step - loss: 4.0547\n",
      " - f1: 57.75\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          B       0.60      0.54      0.57       600\n",
      "          I       0.63      0.57      0.60       269\n",
      "\n",
      "avg / total       0.61      0.55      0.58       869\n",
      "\n",
      "Epoch 15/50\n",
      "63/63 [==============================] - 16s 257ms/step - loss: 4.0470\n",
      " - f1: 57.30\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          B       0.70      0.46      0.55       600\n",
      "          I       0.64      0.58      0.61       269\n",
      "\n",
      "avg / total       0.68      0.49      0.57       869\n",
      "\n",
      "Epoch 16/50\n",
      "63/63 [==============================] - 15s 233ms/step - loss: 4.0431\n",
      " - f1: 57.54\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          B       0.67      0.50      0.57       600\n",
      "          I       0.60      0.57      0.58       269\n",
      "\n",
      "avg / total       0.65      0.52      0.58       869\n",
      "\n",
      "Epoch 17/50\n",
      "63/63 [==============================] - 15s 235ms/step - loss: 4.0383\n",
      " - f1: 56.61\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          B       0.61      0.51      0.56       600\n",
      "          I       0.58      0.59      0.59       269\n",
      "\n",
      "avg / total       0.60      0.54      0.57       869\n",
      "\n",
      "Epoch 18/50\n",
      "63/63 [==============================] - 14s 222ms/step - loss: 4.0338\n",
      " - f1: 56.53\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          B       0.60      0.51      0.55       600\n",
      "          I       0.62      0.57      0.59       269\n",
      "\n",
      "avg / total       0.60      0.53      0.56       869\n",
      "\n",
      "Epoch 19/50\n",
      "63/63 [==============================] - 14s 222ms/step - loss: 4.0309\n",
      " - f1: 56.07\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          B       0.64      0.47      0.55       600\n",
      "          I       0.67      0.53      0.59       269\n",
      "\n",
      "avg / total       0.65      0.49      0.56       869\n",
      "\n",
      "Epoch 20/50\n",
      "63/63 [==============================] - 16s 250ms/step - loss: 4.0305\n",
      " - f1: 57.06\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          B       0.59      0.54      0.56       600\n",
      "          I       0.61      0.56      0.58       269\n",
      "\n",
      "avg / total       0.60      0.54      0.57       869\n",
      "\n",
      "Epoch 21/50\n",
      "63/63 [==============================] - 16s 260ms/step - loss: 4.0283\n",
      " - f1: 56.24\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          B       0.57      0.54      0.56       600\n",
      "          I       0.62      0.54      0.58       269\n",
      "\n",
      "avg / total       0.59      0.54      0.56       869\n",
      "\n",
      "Epoch 22/50\n",
      "63/63 [==============================] - 15s 239ms/step - loss: 4.0243\n",
      " - f1: 55.53\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          B       0.64      0.46      0.53       600\n",
      "          I       0.66      0.55      0.60       269\n",
      "\n",
      "avg / total       0.64      0.49      0.55       869\n",
      "\n",
      "Epoch 23/50\n",
      "63/63 [==============================] - 14s 228ms/step - loss: 4.0230\n",
      " - f1: 56.55\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          B       0.56      0.55      0.55       600\n",
      "          I       0.66      0.54      0.59       269\n",
      "\n",
      "avg / total       0.59      0.55      0.57       869\n",
      "\n",
      "Epoch 24/50\n",
      "63/63 [==============================] - 16s 252ms/step - loss: 4.0226\n",
      " - f1: 53.86\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          B       0.61      0.45      0.52       600\n",
      "          I       0.68      0.52      0.59       269\n",
      "\n",
      "avg / total       0.63      0.47      0.54       869\n",
      "\n",
      "Epoch 25/50\n",
      "63/63 [==============================] - 16s 255ms/step - loss: 4.0217\n",
      " - f1: 56.42\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          B       0.59      0.52      0.55       600\n",
      "          I       0.64      0.54      0.59       269\n",
      "\n",
      "avg / total       0.61      0.53      0.56       869\n",
      "\n",
      "Epoch 26/50\n",
      "63/63 [==============================] - 16s 254ms/step - loss: 4.0194\n",
      " - f1: 56.30\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          B       0.60      0.50      0.55       600\n",
      "          I       0.62      0.58      0.60       269\n",
      "\n",
      "avg / total       0.61      0.52      0.56       869\n",
      "\n",
      "Epoch 27/50\n",
      "63/63 [==============================] - 18s 282ms/step - loss: 4.0172\n",
      " - f1: 55.33\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          B       0.59      0.51      0.54       600\n",
      "          I       0.62      0.54      0.57       269\n",
      "\n",
      "avg / total       0.60      0.52      0.55       869\n",
      "\n",
      "Epoch 28/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 18s 283ms/step - loss: 4.0149\n",
      " - f1: 56.32\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          B       0.58      0.53      0.55       600\n",
      "          I       0.61      0.57      0.59       269\n",
      "\n",
      "avg / total       0.59      0.54      0.56       869\n",
      "\n",
      "Epoch 29/50\n",
      "63/63 [==============================] - 18s 278ms/step - loss: 4.0144\n",
      " - f1: 55.27\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          B       0.62      0.49      0.55       600\n",
      "          I       0.60      0.53      0.56       269\n",
      "\n",
      "avg / total       0.61      0.50      0.55       869\n",
      "\n",
      "Epoch 30/50\n",
      "63/63 [==============================] - 16s 256ms/step - loss: 4.0142\n",
      " - f1: 56.02\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          B       0.55      0.55      0.55       600\n",
      "          I       0.63      0.55      0.59       269\n",
      "\n",
      "avg / total       0.57      0.55      0.56       869\n",
      "\n",
      "Epoch 31/50\n",
      "63/63 [==============================] - 18s 291ms/step - loss: 4.0143\n",
      " - f1: 55.98\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          B       0.64      0.46      0.53       600\n",
      "          I       0.66      0.57      0.61       269\n",
      "\n",
      "avg / total       0.65      0.49      0.56       869\n",
      "\n",
      "Epoch 32/50\n",
      "63/63 [==============================] - 16s 258ms/step - loss: 4.0134\n",
      " - f1: 56.81\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          B       0.59      0.51      0.55       600\n",
      "          I       0.65      0.58      0.61       269\n",
      "\n",
      "avg / total       0.61      0.53      0.57       869\n",
      "\n",
      "Epoch 33/50\n",
      "63/63 [==============================] - 16s 248ms/step - loss: 4.0136\n",
      " - f1: 56.40\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          B       0.60      0.51      0.55       600\n",
      "          I       0.63      0.57      0.60       269\n",
      "\n",
      "avg / total       0.61      0.52      0.56       869\n",
      "\n",
      "Epoch 34/50\n",
      "63/63 [==============================] - 15s 235ms/step - loss: 4.0149\n",
      " - f1: 55.69\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          B       0.61      0.49      0.54       600\n",
      "          I       0.59      0.58      0.59       269\n",
      "\n",
      "avg / total       0.60      0.52      0.56       869\n",
      "\n",
      "Epoch 35/50\n",
      "63/63 [==============================] - 14s 228ms/step - loss: 4.0134\n",
      " - f1: 55.26\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          B       0.63      0.47      0.54       600\n",
      "          I       0.63      0.54      0.58       269\n",
      "\n",
      "avg / total       0.63      0.49      0.55       869\n",
      "\n",
      "Epoch 36/50\n",
      "63/63 [==============================] - 14s 222ms/step - loss: 4.0127\n",
      " - f1: 55.75\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          B       0.64      0.47      0.54       600\n",
      "          I       0.61      0.56      0.59       269\n",
      "\n",
      "avg / total       0.63      0.50      0.56       869\n",
      "\n",
      "Epoch 37/50\n",
      "63/63 [==============================] - 15s 240ms/step - loss: 4.0124\n",
      " - f1: 56.29\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          B       0.60      0.50      0.54       600\n",
      "          I       0.65      0.57      0.61       269\n",
      "\n",
      "avg / total       0.61      0.52      0.56       869\n",
      "\n",
      "Epoch 38/50\n",
      "63/63 [==============================] - 15s 242ms/step - loss: 4.0105\n",
      " - f1: 56.87\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          B       0.66      0.47      0.55       600\n",
      "          I       0.64      0.58      0.61       269\n",
      "\n",
      "avg / total       0.65      0.51      0.57       869\n",
      "\n",
      "Epoch 39/50\n",
      "63/63 [==============================] - 16s 248ms/step - loss: 4.0105\n",
      " - f1: 55.29\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          B       0.58      0.50      0.54       600\n",
      "          I       0.64      0.54      0.59       269\n",
      "\n",
      "avg / total       0.60      0.51      0.55       869\n",
      "\n",
      "Epoch 40/50\n",
      "63/63 [==============================] - 15s 233ms/step - loss: 4.0111\n",
      " - f1: 55.86\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          B       0.64      0.47      0.54       600\n",
      "          I       0.62      0.57      0.59       269\n",
      "\n",
      "avg / total       0.63      0.50      0.56       869\n",
      "\n",
      "Epoch 41/50\n",
      "63/63 [==============================] - 15s 236ms/step - loss: 4.0120\n",
      " - f1: 55.26\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          B       0.61      0.48      0.54       600\n",
      "          I       0.62      0.56      0.59       269\n",
      "\n",
      "avg / total       0.61      0.50      0.55       869\n",
      "\n",
      "Epoch 42/50\n",
      "63/63 [==============================] - 14s 221ms/step - loss: 4.0103\n",
      " - f1: 54.84\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          B       0.57      0.50      0.53       600\n",
      "          I       0.63      0.54      0.58       269\n",
      "\n",
      "avg / total       0.59      0.51      0.55       869\n",
      "\n",
      "Epoch 43/50\n",
      "63/63 [==============================] - 14s 229ms/step - loss: 4.0096\n",
      " - f1: 55.76\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          B       0.60      0.50      0.54       600\n",
      "          I       0.61      0.56      0.59       269\n",
      "\n",
      "avg / total       0.60      0.52      0.56       869\n",
      "\n",
      "Epoch 44/50\n",
      "63/63 [==============================] - 15s 238ms/step - loss: 4.0102\n",
      " - f1: 55.75\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          B       0.62      0.49      0.55       600\n",
      "          I       0.62      0.54      0.58       269\n",
      "\n",
      "avg / total       0.62      0.51      0.56       869\n",
      "\n",
      "Epoch 45/50\n",
      "63/63 [==============================] - 15s 243ms/step - loss: 4.0106\n",
      " - f1: 55.78\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          B       0.58      0.51      0.54       600\n",
      "          I       0.66      0.54      0.59       269\n",
      "\n",
      "avg / total       0.60      0.52      0.56       869\n",
      "\n",
      "Epoch 46/50\n",
      "63/63 [==============================] - 15s 233ms/step - loss: 4.0111\n",
      " - f1: 56.20\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          B       0.57      0.53      0.55       600\n",
      "          I       0.62      0.57      0.59       269\n",
      "\n",
      "avg / total       0.59      0.54      0.56       869\n",
      "\n",
      "Epoch 47/50\n",
      "63/63 [==============================] - 15s 245ms/step - loss: 4.0102\n",
      " - f1: 55.32\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          B       0.58      0.49      0.54       600\n",
      "          I       0.66      0.54      0.59       269\n",
      "\n",
      "avg / total       0.61      0.51      0.55       869\n",
      "\n",
      "Epoch 48/50\n",
      "63/63 [==============================] - 14s 228ms/step - loss: 4.0096\n",
      " - f1: 57.67\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          B       0.62      0.51      0.56       600\n",
      "          I       0.62      0.60      0.61       269\n",
      "\n",
      "avg / total       0.62      0.54      0.58       869\n",
      "\n",
      "Epoch 49/50\n",
      "63/63 [==============================] - 16s 252ms/step - loss: 4.0095\n",
      " - f1: 56.74\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          B       0.59      0.51      0.55       600\n",
      "          I       0.63      0.59      0.61       269\n",
      "\n",
      "avg / total       0.60      0.54      0.57       869\n",
      "\n",
      "Epoch 50/50\n",
      "63/63 [==============================] - 15s 239ms/step - loss: 4.0096\n",
      " - f1: 58.08\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          B       0.57      0.55      0.56       600\n",
      "          I       0.64      0.61      0.62       269\n",
      "\n",
      "avg / total       0.59      0.57      0.58       869\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use pre-trained word embeddings\n",
    "model = anago.Sequence(embeddings=embeddings, word_embedding_dim=300)\n",
    "model.fit(x_train, y_train, x_test, y_test, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_test\n",
    "\n",
    "# Sentence class\n",
    "class SentenceGetter(object):\n",
    "\n",
    "    def __init__(self, data):\n",
    "        self.n_sent = 1\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "        agg_func = lambda s: [(w, t) for w, t in zip(s[\"Word\"].values.tolist(),\n",
    "#                                                            s[\"POS\"].values.tolist(),\n",
    "                                                           s[\"Tag\"].values.tolist())]\n",
    "        self.grouped = self.data.groupby(\"Sentence #\").apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "\n",
    "    def get_next(self):\n",
    "        try:\n",
    "            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
    "            self.n_sent += 1\n",
    "            return s\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "getter = SentenceGetter(data)\n",
    "sentences = getter.sentences # get all sentences\n",
    "   \n",
    "# Word2inx & Padding for X\n",
    "X = [[word2idx.get(w[0], 0) for w in s] for s in sentences]\n",
    "X_test = pad_sequences(maxlen=max_len, sequences=X, padding=\"post\", value=0)\n",
    "\n",
    "# Word2inx & Padding for y\n",
    "y = [[tag2idx[w[1]] for w in s] for s in sentences]\n",
    "y = pad_sequences(maxlen=max_len, sequences=y, padding=\"post\", value=0)\n",
    "\n",
    "# Get one-hot labels\n",
    "y_test = [to_categorical(i, num_classes=n_tags) for i in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('serves', 'O'), ('really', 'O'), ('good', 'O'), ('sushi', 'B'), ('.', 'O')]\n",
      "[1183 3401 2591  176 1280    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "[1 1 1 3 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0]\n"
     ]
    }
   ],
   "source": [
    "print(sentences[1])\n",
    "print(X_test[1])\n",
    "print(np.argmax(y_test[1], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('green', 'B'), ('tea', 'I'), ('creme', 'I'), ('brulee', 'I'), ('is', 'O'), ('a', 'B'), ('must', 'O'), ('!', 'O')]\n",
      "[3286 1088    0    0  539 2177 3012 3425    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0]\n",
      "['B', 'I', 'I', 'I', 'O', 'B', 'O', 'O']\n",
      "['I', 'I', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "# Predictions.\n",
    "idx2word = {value: key for key, value in word2idx.items()}\n",
    "idx2tag = {value: key for key, value in tag2idx.items()}\n",
    "\n",
    "\n",
    "true_all = np.argmax(y_test, -1)\n",
    "\n",
    "true_all_tags = [[idx2tag[idx] for idx in s if idx!=0] for s in true_all]\n",
    "\n",
    "p_all = model.predict(np.array(X_test)) # (4796, 75, 18)\n",
    "p_all= np.argmax(p_all, axis=-1) # (4796, 75)\n",
    "p_all_tags = [[idx2tag[idx] for idx in s] for s in p_all] # ['B-gpe', 'O', 'O', 'O']\n",
    "\n",
    "for i, true in enumerate(true_all_tags):\n",
    "    length = len(true)\n",
    "    p_all_tags[i] = p_all_tags[i][:length]\n",
    "\n",
    "p_all_tags = [[x.replace('<pad>', 'O') for x in s] for s in p_all_tags]\n",
    "\n",
    "# for (true_tag, p)\n",
    "\n",
    "print(sentences[3])\n",
    "print(X_test[3])\n",
    "print(true_all_tags[3])\n",
    "print(p_all_tags[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word           ||True ||Pred\n",
      "==============================\n",
      "green          : B     I\n",
      "tea            : I     I\n",
      "creme          : I     O\n",
      "brulee         : I     O\n",
      "is             : O     O\n",
      "a              : B     O\n",
      "must           : O     O\n",
      "!              : O     O\n"
     ]
    }
   ],
   "source": [
    "print(\"{:15}||{:5}||{}\".format(\"Word\", \"True\", \"Pred\"))\n",
    "print(30 * \"=\")\n",
    "for w, t, pred in zip(sentences[3], true_all_tags[3], p_all_tags[3]):\n",
    "    if w != 0:\n",
    "        print(\"{:15}: {:5} {}\".format(w[0], w[1], pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41892832289492\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          B       0.58      0.34      0.42       599\n",
      "          I       0.45      0.37      0.41       269\n",
      "\n",
      "avg / total       0.54      0.35      0.42       868\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "from seqeval.metrics import f1_score, classification_report\n",
    "print(f1_score(true_all_tags, p_all_tags))\n",
    "print(classification_report(true_all_tags, p_all_tags))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
