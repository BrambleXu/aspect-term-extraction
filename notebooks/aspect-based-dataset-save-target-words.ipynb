{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will save the target word in each sentence. Because we want to augment the embedding wegiht of target word to evaluate whether or not the attention is useful. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 raw data to soup object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/smap10/Project/aspect-extraction/raw-data/semeval-2016/train.xml')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_file = Path.cwd().parent.joinpath('raw-data/semeval-2016/train.xml')\n",
    "train_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = None\n",
    "with train_file.open(encoding=\"utf-8\") as f:\n",
    "    soup = BeautifulSoup(f.read().strip(), \"lxml-xml\")\n",
    "if soup is None:\n",
    "    raise Exception(\"Can't read xml file\")\n",
    "sentence_nodes = soup.find_all(\"sentence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sentence id=\"1004293:0\">\n",
      "<text>Judging from previous posts this used to be a good place, but not any longer.</text>\n",
      "<Opinions>\n",
      "<Opinion category=\"RESTAURANT#GENERAL\" from=\"51\" polarity=\"negative\" target=\"place\" to=\"56\"/>\n",
      "</Opinions>\n",
      "</sentence>\n",
      "\n",
      "<sentence id=\"1004293:1\">\n",
      "<text>We, there were four of us, arrived at noon - the place was empty - and the staff acted like we were imposing on them and they were very rude.</text>\n",
      "<Opinions>\n",
      "<Opinion category=\"SERVICE#GENERAL\" from=\"75\" polarity=\"negative\" target=\"staff\" to=\"80\"/>\n",
      "</Opinions>\n",
      "</sentence>\n",
      "\n",
      "<sentence id=\"1004293:2\">\n",
      "<text>They never brought us complimentary noodles, ignored repeated requests for sugar, and threw our dishes on the table.</text>\n",
      "<Opinions>\n",
      "<Opinion category=\"SERVICE#GENERAL\" from=\"0\" polarity=\"negative\" target=\"NULL\" to=\"0\"/>\n",
      "</Opinions>\n",
      "</sentence>\n",
      "\n",
      "<sentence id=\"1004293:3\">\n",
      "<text>The food was lousy - too sweet or too salty and the portions tiny.</text>\n",
      "<Opinions>\n",
      "<Opinion category=\"FOOD#QUALITY\" from=\"4\" polarity=\"negative\" target=\"food\" to=\"8\"/>\n",
      "<Opinion category=\"FOOD#STYLE_OPTIONS\" from=\"52\" polarity=\"negative\" target=\"portions\" to=\"60\"/>\n",
      "</Opinions>\n",
      "</sentence>\n",
      "\n",
      "<sentence id=\"1004293:4\">\n",
      "<text>After all that, they complained to me about the small tip.</text>\n",
      "<Opinions>\n",
      "<Opinion category=\"SERVICE#GENERAL\" from=\"0\" polarity=\"negative\" target=\"NULL\" to=\"0\"/>\n",
      "</Opinions>\n",
      "</sentence>\n",
      "\n",
      "<sentence id=\"1004293:5\">\n",
      "<text>Avoid this place!</text>\n",
      "<Opinions>\n",
      "<Opinion category=\"RESTAURANT#GENERAL\" from=\"11\" polarity=\"negative\" target=\"place\" to=\"16\"/>\n",
      "</Opinions>\n",
      "</sentence>\n",
      "\n",
      "<sentence id=\"1014458:0\">\n",
      "<text>I have eaten at Saul, many times, the food is always consistently, outrageously good.</text>\n",
      "<Opinions>\n",
      "<Opinion category=\"FOOD#QUALITY\" from=\"38\" polarity=\"positive\" target=\"food\" to=\"42\"/>\n",
      "</Opinions>\n",
      "</sentence>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, node in enumerate(sentence_nodes):\n",
    "    print(node)\n",
    "    print()\n",
    "    if i > 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2  convert soup object to a list of dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soup2dict(sentence_nodes):\n",
    "    \"\"\"\n",
    "    Input: a soup object, e.g. soup.find_all(\"sentence\")\n",
    "    Output: a list of dictionaries, contains id, text, aspect terms\n",
    "    \"\"\"\n",
    "    sentences = []\n",
    "    i = 0\n",
    "    for n in sentence_nodes:\n",
    "        i += 1\n",
    "        sentence = {}\n",
    "        aspect_term = []\n",
    "        sentence['id'] = i\n",
    "        sentence['text'] = n.find('text').string\n",
    "        if n.find('Opinions'):\n",
    "            for c in n.find('Opinions').contents:\n",
    "                if c.name == 'Opinion':\n",
    "                    if c['target'] not in aspect_term:\n",
    "                        aspect_term.append(c['target'])\n",
    "\n",
    "        sentence['aspect'] = aspect_term\n",
    "        sentences.append(sentence)\n",
    "        \n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = soup2dict(sentence_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'aspect': ['place'],\n",
       "  'id': 1,\n",
       "  'text': 'Judging from previous posts this used to be a good place, but not any longer.'},\n",
       " {'aspect': ['staff'],\n",
       "  'id': 2,\n",
       "  'text': 'We, there were four of us, arrived at noon - the place was empty - and the staff acted like we were imposing on them and they were very rude.'},\n",
       " {'aspect': ['NULL'],\n",
       "  'id': 3,\n",
       "  'text': 'They never brought us complimentary noodles, ignored repeated requests for sugar, and threw our dishes on the table.'},\n",
       " {'aspect': ['food', 'portions'],\n",
       "  'id': 4,\n",
       "  'text': 'The food was lousy - too sweet or too salty and the portions tiny.'},\n",
       " {'aspect': ['NULL'],\n",
       "  'id': 5,\n",
       "  'text': 'After all that, they complained to me about the small tip.'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See how many sentences contain aspect terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "791\n",
      "1209\n"
     ]
    }
   ],
   "source": [
    "# No sentence contain two NULL target (aspect term)\n",
    "aspect_zero = 0\n",
    "aspect_one = 0\n",
    "\n",
    "for s in sentences:\n",
    "    # aspect == [] or aspect == ['NULL']\n",
    "    if len(s['aspect'])==0 or s['aspect'][0] == 'NULL':\n",
    "        aspect_zero += 1\n",
    "    else:\n",
    "        aspect_one += 1\n",
    "        \n",
    "print(len(sentences)) # Total 2000 sentences\n",
    "print(aspect_zero) # xxx sentences have no aspect term\n",
    "print(aspect_one) # xxx sentences have at least 1 aspect term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xml2soup(path):\n",
    "    soup = None\n",
    "    with path.open(encoding=\"utf-8\") as f:\n",
    "        soup = BeautifulSoup(f.read().strip(), \"lxml-xml\")\n",
    "    if soup is None:\n",
    "        raise Exception(\"Can't read xml file\")\n",
    "    sentence_nodes = soup.find_all(\"sentence\")\n",
    "\n",
    "    return sentence_nodes\n",
    "\n",
    "def soup2dict(sentence_nodes):\n",
    "    \"\"\"\n",
    "    Input: a soup object, e.g. soup.find_all(\"sentence\")\n",
    "    Output: a list of dictionaries, contains id, text, aspect terms\n",
    "    \"\"\"\n",
    "    sentences = []\n",
    "    i = 0\n",
    "    for n in sentence_nodes:\n",
    "        i += 1\n",
    "        sentence = {}\n",
    "        aspect_term = []\n",
    "        sentence['id'] = i\n",
    "        sentence['text'] = n.find('text').string\n",
    "        if n.find('Opinions'):\n",
    "            for c in n.find('Opinions').contents:\n",
    "                if c.name == 'Opinion':\n",
    "                    if c['target'] not in aspect_term:\n",
    "                        aspect_term.append(c['target'])\n",
    "\n",
    "        sentence['aspect'] = aspect_term\n",
    "        sentences.append(sentence)\n",
    "        \n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 save target word as a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_target(sentences):\n",
    "    target_list = []\n",
    "    for s in sentences:\n",
    "        # aspect == [] or aspect == ['NUMM']\n",
    "        target_list.append(s['aspect'])\n",
    "    return target_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path\n",
    "train_path = Path.cwd().parent.joinpath('raw-data/semeval-2016/train.xml')\n",
    "test_path = Path.cwd().parent.joinpath('raw-data/semeval-2016/test.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# soup nodes\n",
    "train_nodes = xml2soup(train_path)\n",
    "test_nodes = xml2soup(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentence dictionary\n",
    "train_sentences = soup2dict(train_nodes)\n",
    "test_sentences = soup2dict(test_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save word in each aspect\n",
    "train_target = save_target(train_sentences)\n",
    "test_target = save_target(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "[['place'], ['staff'], ['NULL'], ['food', 'portions'], ['NULL']]\n",
      "676\n",
      "[['NULL'], ['sushi'], ['portions'], ['Green Tea creme brulee'], ['NULL']]\n"
     ]
    }
   ],
   "source": [
    "print(len(train_target))\n",
    "print(train_target[:5])\n",
    "print(len(test_target))\n",
    "print(test_target[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to file\n",
    "train_target = np.array(train_target)\n",
    "test_target = np.array(test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('train_target.npy', train_target) \n",
    "np.save('test_target.npy', test_target) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anago-embedding.ipynb\r\n",
      "aspect-based-dataset-IBO-Readable-with-target.ipynb\r\n",
      "aspect-based-dataset-IBO-Readable.ipynb\r\n",
      "aspect-based-dataset-IBO.ipynb\r\n",
      "bi-lstm-crf-embedding.ipynb\r\n",
      "bi-lstm-crf.ipynb\r\n",
      "load-large-file-with-progress-bar.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
