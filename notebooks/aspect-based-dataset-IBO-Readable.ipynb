{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 raw data to soup object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/smap10/Project/aspect-extraction/raw-data/semeval-2016/train.xml')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_file = Path.cwd().parent.joinpath('raw-data/semeval-2016/train.xml')\n",
    "train_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = None\n",
    "with train_file.open(encoding=\"utf-8\") as f:\n",
    "    soup = BeautifulSoup(f.read().strip(), \"lxml-xml\")\n",
    "if soup is None:\n",
    "    raise Exception(\"Can't read xml file\")\n",
    "sentence_nodes = soup.find_all(\"sentence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sentence id=\"1004293:0\">\n",
      "<text>Judging from previous posts this used to be a good place, but not any longer.</text>\n",
      "<Opinions>\n",
      "<Opinion category=\"RESTAURANT#GENERAL\" from=\"51\" polarity=\"negative\" target=\"place\" to=\"56\"/>\n",
      "</Opinions>\n",
      "</sentence>\n",
      "\n",
      "<sentence id=\"1004293:1\">\n",
      "<text>We, there were four of us, arrived at noon - the place was empty - and the staff acted like we were imposing on them and they were very rude.</text>\n",
      "<Opinions>\n",
      "<Opinion category=\"SERVICE#GENERAL\" from=\"75\" polarity=\"negative\" target=\"staff\" to=\"80\"/>\n",
      "</Opinions>\n",
      "</sentence>\n",
      "\n",
      "<sentence id=\"1004293:2\">\n",
      "<text>They never brought us complimentary noodles, ignored repeated requests for sugar, and threw our dishes on the table.</text>\n",
      "<Opinions>\n",
      "<Opinion category=\"SERVICE#GENERAL\" from=\"0\" polarity=\"negative\" target=\"NULL\" to=\"0\"/>\n",
      "</Opinions>\n",
      "</sentence>\n",
      "\n",
      "<sentence id=\"1004293:3\">\n",
      "<text>The food was lousy - too sweet or too salty and the portions tiny.</text>\n",
      "<Opinions>\n",
      "<Opinion category=\"FOOD#QUALITY\" from=\"4\" polarity=\"negative\" target=\"food\" to=\"8\"/>\n",
      "<Opinion category=\"FOOD#STYLE_OPTIONS\" from=\"52\" polarity=\"negative\" target=\"portions\" to=\"60\"/>\n",
      "</Opinions>\n",
      "</sentence>\n",
      "\n",
      "<sentence id=\"1004293:4\">\n",
      "<text>After all that, they complained to me about the small tip.</text>\n",
      "<Opinions>\n",
      "<Opinion category=\"SERVICE#GENERAL\" from=\"0\" polarity=\"negative\" target=\"NULL\" to=\"0\"/>\n",
      "</Opinions>\n",
      "</sentence>\n",
      "\n",
      "<sentence id=\"1004293:5\">\n",
      "<text>Avoid this place!</text>\n",
      "<Opinions>\n",
      "<Opinion category=\"RESTAURANT#GENERAL\" from=\"11\" polarity=\"negative\" target=\"place\" to=\"16\"/>\n",
      "</Opinions>\n",
      "</sentence>\n",
      "\n",
      "<sentence id=\"1014458:0\">\n",
      "<text>I have eaten at Saul, many times, the food is always consistently, outrageously good.</text>\n",
      "<Opinions>\n",
      "<Opinion category=\"FOOD#QUALITY\" from=\"38\" polarity=\"positive\" target=\"food\" to=\"42\"/>\n",
      "</Opinions>\n",
      "</sentence>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, node in enumerate(sentence_nodes):\n",
    "    print(node)\n",
    "    print()\n",
    "    if i > 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2  convert soup object to a list of dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soup2dict(sentence_nodes):\n",
    "    \"\"\"\n",
    "    Input: a soup object, e.g. soup.find_all(\"sentence\")\n",
    "    Output: a list of dictionaries, contains id, text, aspect terms\n",
    "    \"\"\"\n",
    "    sentences = []\n",
    "    i = 0\n",
    "    for n in sentence_nodes:\n",
    "        i += 1\n",
    "        sentence = {}\n",
    "        aspect_term = []\n",
    "        sentence['id'] = i\n",
    "        sentence['text'] = n.find('text').string\n",
    "        if n.find('Opinions'):\n",
    "            for c in n.find('Opinions').contents:\n",
    "                if c.name == 'Opinion':\n",
    "                    if c['target'] not in aspect_term:\n",
    "                        aspect_term.append(c['target'])\n",
    "\n",
    "        sentence['aspect'] = aspect_term\n",
    "        sentences.append(sentence)\n",
    "        \n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = soup2dict(sentence_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'aspect': ['place'],\n",
       "  'id': 1,\n",
       "  'text': 'Judging from previous posts this used to be a good place, but not any longer.'},\n",
       " {'aspect': ['staff'],\n",
       "  'id': 2,\n",
       "  'text': 'We, there were four of us, arrived at noon - the place was empty - and the staff acted like we were imposing on them and they were very rude.'},\n",
       " {'aspect': ['NULL'],\n",
       "  'id': 3,\n",
       "  'text': 'They never brought us complimentary noodles, ignored repeated requests for sugar, and threw our dishes on the table.'},\n",
       " {'aspect': ['food', 'portions'],\n",
       "  'id': 4,\n",
       "  'text': 'The food was lousy - too sweet or too salty and the portions tiny.'},\n",
       " {'aspect': ['NULL'],\n",
       "  'id': 5,\n",
       "  'text': 'After all that, they complained to me about the small tip.'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See how many sentences contain aspect terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "791\n",
      "1209\n"
     ]
    }
   ],
   "source": [
    "# No sentence contain two NULL target (aspect term)\n",
    "aspect_zero = 0\n",
    "aspect_one = 0\n",
    "\n",
    "for s in sentences:\n",
    "    # aspect == [] or aspect == ['NULL']\n",
    "    if len(s['aspect'])==0 or s['aspect'][0] == 'NULL':\n",
    "        aspect_zero += 1\n",
    "    else:\n",
    "        aspect_one += 1\n",
    "        \n",
    "print(len(sentences)) # Total 2000 sentences\n",
    "print(aspect_zero) # xxx sentences have no aspect term\n",
    "print(aspect_one) # xxx sentences have at least 1 aspect term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have total 2000 sentences, and only 1209 sentences have 1 aspect term at least."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 list to dataframe\n",
    "\n",
    "## 3.1 split text to words\n",
    "\n",
    "Here we preserve the punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split2words(s_text):\n",
    "    \"\"\"Split string with white and prereserve the punctuation\n",
    "    Input:\n",
    "        s_text: string, a sentence, e.g. Judging from previous posts this used to be a good place, but not any longer.\n",
    "    Output:\n",
    "        words: a list of words, e.g. ['judging', 'from', 'previous', 'posts', 'this', 'used', 'to', 'be', 'a', 'good', 'place', ',', 'but', 'not', 'any', 'longer', '.']\n",
    "    \"\"\"\n",
    "    s_text = re.sub('([.,!?()])', r' \\1 ', s_text) # match the punctuation characters and surround them by spaces,\n",
    "    s_text = re.sub('\\s{2,}', ' ', s_text)         # collapse multiple spaces to one space\n",
    "    words = s_text.lower().split()\n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 taggin word with IOB format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tagging_IOB(s, aspects):\n",
    "    \"\"\"Assigning IOB tag to each word in s\n",
    "    Input: \n",
    "        s: sentences, a list of words, e.g. ['judging', 'from', 'previous', 'posts']\n",
    "        aspects: a list of aspect term, e.g. ['a good place', 'Posts']\n",
    "    Output:\n",
    "        tag: a list of tag, e.g. ['O', 'O', 'O', 'B']\n",
    "    \"\"\"\n",
    "    tags = ['O'] * len(s)\n",
    "\n",
    "    for aspect in aspects:\n",
    "        pre_index = 0\n",
    "        for word in s: \n",
    "            if word in aspect: # 'good' in 'a good place'\n",
    "                cur_index = s.index(word) \n",
    "                if cur_index - pre_index == 1: # inside an aspect term\n",
    "                    tags[cur_index] = 'I'\n",
    "                else:                       # beginning of an aspect term\n",
    "                    tags[cur_index] = 'B'\n",
    "                pre_index = cur_index \n",
    "    return tags\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3 convert a list of dict to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict2df(sentences):\n",
    "    \"\"\"Convert list of dict to dataframe\n",
    "    Input: \n",
    "        sentences: a list of dictionaries, contains id, text, aspect terms. The output of raw2dict\n",
    "    Output:\n",
    "        data: a dataframe with three columns, sentence id, words, tag with IOB format\n",
    "    \"\"\"\n",
    "    data = pd.DataFrame()\n",
    "    for s in sentences:\n",
    "        sentence = {}\n",
    "        sentence['Sentence #'] = s['id']\n",
    "        sentence['Word'] = split2words(s['text'])  # split text to words\n",
    "        s_length = len(sentence['Word']) # the length of sentence, used to generate tag\n",
    "        if len(s['aspect'])==0 or s['aspect'][0] == 'NULL': # tagging: if no aspect term\n",
    "            sentence['Tag'] = ['O'] * s_length\n",
    "        else:                                               # IOB format tag if aspect exist\n",
    "            aspect_terms = [x.lower() for x in s['aspect']]  \n",
    "            sentence['Tag'] = tagging_IOB(sentence['Word'], aspect_terms)\n",
    "\n",
    "        # convert each setence to dataframe \n",
    "        sentence_df = pd.DataFrame.from_dict(sentence)\n",
    "        data = data.append(sentence_df, ignore_index=True)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dict2df(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28641</th>\n",
       "      <td>2000</td>\n",
       "      <td>O</td>\n",
       "      <td>would</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28642</th>\n",
       "      <td>2000</td>\n",
       "      <td>O</td>\n",
       "      <td>retrain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28643</th>\n",
       "      <td>2000</td>\n",
       "      <td>O</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28644</th>\n",
       "      <td>2000</td>\n",
       "      <td>B</td>\n",
       "      <td>staff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28645</th>\n",
       "      <td>2000</td>\n",
       "      <td>O</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Sentence # Tag     Word\n",
       "28641        2000   O    would\n",
       "28642        2000   O  retrain\n",
       "28643        2000   O      the\n",
       "28644        2000   B    staff\n",
       "28645        2000   O        ."
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Sum it up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 raw data to soup\n",
    "\n",
    "train_file = Path.cwd().parent.joinpath('raw-data/semeval-2016/train.xml')\n",
    "soup = None\n",
    "with train_file.open(encoding=\"utf-8\") as f:\n",
    "    soup = BeautifulSoup(f.read().strip(), \"lxml-xml\")\n",
    "if soup is None:\n",
    "    raise Exception(\"Can't read xml file\")\n",
    "sentence_nodes = soup.find_all(\"sentence\")\n",
    "\n",
    "# 2  convert soup object to a list of dictionaries\n",
    "sentences = soup2dict(sentence_nodes)\n",
    "\n",
    "# 3 list to dataframe\n",
    "data = dict2df(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>judging</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>from</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>previous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>posts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>used</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sentence # Tag      Word\n",
       "0           1   O   judging\n",
       "1           1   O      from\n",
       "2           1   O  previous\n",
       "3           1   O     posts\n",
       "4           1   O      this\n",
       "5           1   O      used\n",
       "6           1   O        to\n",
       "7           1   O        be\n",
       "8           1   B         a\n",
       "9           1   O      good"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Convert step 4 to a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_path):\n",
    "    # 1 raw data to soup\n",
    "    soup = None\n",
    "    with file_path.open(encoding=\"utf-8\") as f:\n",
    "        soup = BeautifulSoup(f.read().strip(), \"lxml-xml\")\n",
    "    if soup is None:\n",
    "        raise Exception(\"Can't read xml file\")\n",
    "    sentence_nodes = soup.find_all(\"sentence\")\n",
    "\n",
    "    # 2  convert soup object to a list of dictionaries\n",
    "    sentences = soup2dict(sentence_nodes)\n",
    "\n",
    "    # 3 list to dataframe\n",
    "    data = dict2df(sentences)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Test read_data on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = Path.cwd().parent.joinpath('raw-data/semeval-2016/test.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = read_data(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9864</th>\n",
       "      <td>676</td>\n",
       "      <td>O</td>\n",
       "      <td>was</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9865</th>\n",
       "      <td>676</td>\n",
       "      <td>O</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9866</th>\n",
       "      <td>676</td>\n",
       "      <td>O</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9867</th>\n",
       "      <td>676</td>\n",
       "      <td>O</td>\n",
       "      <td>too</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9868</th>\n",
       "      <td>676</td>\n",
       "      <td>O</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sentence # Tag  Word\n",
       "9864         676   O   was\n",
       "9865         676   O  good\n",
       "9866         676   O     ,\n",
       "9867         676   O   too\n",
       "9868         676   O     ."
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 Save preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file = Path.cwd().parent.joinpath('data/semeval-2016/test.csv')\n",
    "\n",
    "data.to_csv(save_file, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
